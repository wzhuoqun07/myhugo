---
title: "Research in Multimodal Medical AI"
date: 2025-06-02
draft: false
---

# Research in Multimodal Medical AI

Since March 2024, I've been working as a research assistant at **Northwestern University**, contributing to an ambitious project in the field of **multimodal AI for medicine**. Our goal is to develop a **tri-modal deep learning system** that can integrate and analyze:

- **Medical imaging** (e.g., MRI, CT scans)
- **DNA sequences**
- **Natural language** data from clinical reports

## üîç My Focus: Robust DNA Sequence Processing

My specific area of focus is improving how the model handles **DNA sequences**, which pose unique challenges compared to images or text due to their structure and encoding ambiguity.

### Contributions:
- **Explored tokenization strategies** tailored to DNA sequence data, including:
  - Fixed-length k-mer encoding
  - Learnable embedding-based methods
- Evaluated performance impacts on representation learning and downstream classification
- Integrated DNA modalities into a multi-encoder architecture for joint learning

## üî¨ Research Goals and Significance

Multimodal models have immense potential in **precision medicine**, where decisions must consider diverse data sources. By combining image, sequence, and textual data, we aim to create models that are:

- More accurate in diagnosis
- Better at generalizing to rare diseases
- Capable of providing interpretable evidence across modalities

This work is advised by **PhD student Weimin Wu**, and it's part of a broader research initiative within the medical AI group at Northwestern.

_This project has deepened my interest in representation learning and biomedical applications of machine learning._

[‚Üê Back to About](/about/)
